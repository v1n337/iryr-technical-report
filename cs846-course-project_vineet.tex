\documentclass[conference]{IEEEtran}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithmic}
\usepackage{array}
\usepackage{url}
\usepackage{listings}

\begin{document}
\title{Continuous Function Semi-supervised Learning\\ for Sentiment Trend Detection in Big Data}


\author{
	\IEEEauthorblockN{Vineet John}
	\IEEEauthorblockA{
		David R. Cheriton School of Computer Science\\
		University of Waterloo\\
		Waterloo, Ontario N2L 3G1\\
		Email: vineet.john@uwaterloo.ca
	}
}

\maketitle

\begin{abstract}
Commercial establishments (like restaurants, service centers) have several sources of feedback, most of which need not be as structured as feedback provided by services like Yelp, or Amazon. Services like these provide a fine-grained score for product and service ratings. Some sources, however, like social media (Twitter, Facebook), mailing lists (Google Groups), forums (Quora) et al. are sources for much more volumnious but unstructured and unlabelled data. This text could be pipelined into a system with a built-in prediction model, with the objective of generating real-time graphs on opinion and sentiment trends. Although such tasks like the one described about have been explored with respect to document classification problems in the past, the implementation described in this paper, by virtue of learning a continuous function rather than a discrete one, offers a lot more depth of insight as compared to document classification approaches.\\
\end{abstract}


% no keywords
\providecommand{\keywords}[1]{\textbf{\textit{Keywords---}} #1}
\keywords{natural language processing, big data, word embedding, regression, time-series analytics\\}

\IEEEpeerreviewmaketitle

\section{Introduction}
Document labelling and attribute discovery is already a widely researched area in the domain of natural language processing. The most common use-cases of document classification are product \& service review rating predictions, automatic grading of essays, spam detection, plagiarism detection et al. However, most of the current approaches used for these tasks rely on lexicon based methods with a centralized source indicating the weights of a word towards a set of emotion or sentiment. Some other approaches use N-gram count vectorization approaches and document level similarity scores like TF-IDF. However, N-gram approaches only partially model the language context probabilities i.e. the probably of a word occurring next in the corpus depends only on the n-1 words that precede it. However, the Doc2Vec model offers \\

However, models like these are difficult to train for the following reasons:
\begin{itemize}
  \item Having to hand-pick features
  \item Having to manually re-train the models on subset of the features to determine the best-fit
  \item Having to use stepwise regression to eliminate non-relevant features
\end{itemize}

All of the processes described above are time-consuming and tedious. The objective of this work is to implement and evaluate a strategy to effectively eliminate the above steps from the process of training a language model. The proposition is to rely on unsupervised strategies like continuous bag-of-words and the skip-gram model to learn word embeddings, that will serve as a syntactic and semantic proxy for the text being processed. The features thus learnt, can then be used to train regression models to predict text scores.\\


\section{Similar Work}
Most of the similar work in the area of learning word-embeddings is related to classifying documents into a given set of labels or topics. The purpose of this study is to extend the usage of the document vector representation to demonstrating its usage when the response variable (the output of a learning task) a continuous function (document-scoring) rather than discrete values (document classification). This work can be viewed as a generalization of the previous approaches, because this study aims to predict fine-grained document scores, rather than coarse document classifications. \\

Most of the current work in usage of regression techniques on text content are related to metadata or features extraction \cite{su2015genetic} \cite{weissman2016natural}. Similarly there have been several studies to identify document tags using classification techniques\cite{bespalov2011sentiment}\cite{pang2002thumbs}. However, there is a relative absence of studies to evaluate the accuracy of regression models that try to predict a document score using a continuous-function model. \\

As far the the authors are aware, there has been no similar work to test the regression accuracy of paragraph vectors in an experimental research setup before. Hence, the evaluation of the effectiveness of this approach will be assessed using


\section{Problem Statement}
The problem statement can be formulated as an evaluation of Paragraph Vectors \cite{le2014distributed} on a document score regression task to evaluate the accuracy of the prediction model that can be built using the shallow neural network language model learning algorithm previously descibed by Mikolov et al. \cite{mikolov2013efficient}, which was primarily used to unsupervisedly train word embeddings. \\

The prediction scores will be evaluated using the co-efficient of determination metric, also known as the R\textsuperscript{2} metric \cite{cameron1997r}. The hypothesis is to prove that the document ratings have a positive correlation with the vectorized versions of the document text content, because the semantics of positive and negative reviews are expected to be captured by the shallow neural network trained on the corpus.\\


\section{Motivation}

\subsection{Semi-supervised Learning}

\subsection{Continuous function learning}



\section{Challenges}


\section{Background}

\subsection{Word2Vec}

\subsection{Doc2Vec}

\subsection{Statistical Learning Models}

\subsection{Scaling with Spark}





\section{System Architecture}


\section{Implementation}

\subsection{Offline learning model}

\subsection{Online real-time prediction engine}

\subsection{Tech stack}


\section{Evaluation}

\subsection{Testbed}

\subsection{Experimental Results}


\section{Conclusions}


\section{Future Work}


\section{Acknowledgments}
The authors would like to thank...


\bibliographystyle{abbrv}
\bibliography{cs846-course-project_vineet}

\end{document}
